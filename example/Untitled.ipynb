{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71f8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae59715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [nn.Conv2d(in_size, out_size, 3, stride=2, padding=1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.BatchNorm2d(out_size, 0.8))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class RV_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "#         channels_in, self.h, self.w = in_shape\n",
    "#         channels_out, _, _ = out_shape\n",
    "\n",
    "#         self.fc    = nn.Linear(latent_dim, self.h * self.w)\n",
    "\n",
    "        self.down1 = UNetDown(2, 64, normalize=False)\n",
    "        self.down2 = UNetDown(64, 128)\n",
    "        self.down3 = UNetDown(128, 256)\n",
    "        self.down4 = UNetDown(256, 512)\n",
    "        self.down5 = UNetDown(512, 512)\n",
    "        self.down6 = UNetDown(512, 512)\n",
    "        self.down7 = UNetDown(512, 1, normalize=False)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, 3, stride=1, padding=1), nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Propogate noise through fc layer and reshape to img shape\n",
    "#         z = self.fc(z).view(z.size(0), 1, self.h, self.w)\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        \n",
    "        \n",
    "        return self.final(d7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020d3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "692c9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e588fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RV_Dataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        # Cutting image to parts should happen as a preprocess\n",
    "        # Convert to torch tensor\n",
    "        # Normalize IDK\n",
    "        # NO RESIZE\n",
    "        self.transform = transforms.ToTensor(),#transforms.Compose(\n",
    "#             [\n",
    "# #                 transforms.CenterCrop(size),\n",
    "# #                 transforms.Resize((size // ratio, size // ratio), Image.BICUBIC),\n",
    "#                 transforms.ToTensor(),\n",
    "# #                 transforms.Normalize(mean, std),\n",
    "#             ]\n",
    "#         )\n",
    "        self.files = sorted(glob.glob(directory))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img    = fits.open(self.files[index])\n",
    "        target_rv = img.header['RV']\n",
    "        # maybe organize data like this\n",
    "        img_sci = self.transform(img[0].data)\n",
    "        img_ref = self.transform(img[1].data)\n",
    "        out = torch.cat((img_sci,img_ref),0)\n",
    "        return { 'out': out ,'RV': target_rv}\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe6589fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.nddata import Cutout2D\n",
    "from astropy import units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a57b804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c56c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_names,outdir,size):\n",
    "    files = sorted(glob.glob(file_names))\n",
    "    for file_name in files:\n",
    "        tbl = fits.open(file_name)\n",
    "        img_shape = tbl[0].data.shape\n",
    "        integer = (img_shape[1]//size) + 1\n",
    "        delta_x = (img_shape[1] - size)/integer\n",
    "        for i in range(integer):\n",
    "            position = (img_shape[0]/2, size/2 + i * delta_x)\n",
    "            size     = (shape[0], size)\n",
    "            sci   = Cutout2D(tbl['sci'], position, size)\n",
    "            ref   = Cutout2D(tbl['ref'], position, size)\n",
    "            \n",
    "            sci_hdu = fits.ImageHDU(data=sci)\n",
    "            ref_hdu = fits.ImageHDU(data=ref)\n",
    "            \n",
    "            hdu = fits.HDUList([sci_hdu,ref_hdu])\n",
    "            name = path.join(outdir,path.split(file_name)[1] + '_c{}.fits'.format(i))\n",
    "            hdu.header['RV'] = tbl['RV']\n",
    "            hdu.writeto(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2b7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = \n",
    "b1 = \n",
    "b2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RV_Model()\n",
    "mse_loss = torch.nn.L2Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = something\n",
    "dataloader = DataLoader(\n",
    "    RV_Dataset(directory),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8739cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "991ff708",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c54df896fdd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprev_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtarget_rv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "prev_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        imgs = batch['out']\n",
    "        target_rv = batch['RV']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        something = model(imgs)\n",
    "        y = torch.mean(something)\n",
    "        loss = mse_loss(y,target_rv)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        batches_left = n_epochs * len(dataloader) - batches_done\n",
    "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "        prev_time = time.time()\n",
    "\n",
    "        # Print log\n",
    "        sys.stdout.write(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %f] ETA: %s\"\n",
    "            % (\n",
    "                epoch,\n",
    "                n_epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss.item(),\n",
    "                time_left,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e2e95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
